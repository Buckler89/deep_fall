--script-path 			/home/daniele/Repos/deep_fall/scripts
--logging
--search-strategy		random
--rnd-exp-number		40
#--config-file

--score-path			score
--script-path			scripts
--trainset-list 		["trainset.lst"]
--case 				case6
--test-list-names 		["testset_1.lst","testset_2.lst","testset_3.lst","testset_4.lst"]
--dev-list-names 		["devset_1.lst","devset_2.lst","devset_3.lst","devset_4.lst"]
--input-type 			spectrograms

--cnn-input-shape 		[1,129,197]
--conv-layers-numb		[1,2,3]			# pick one of v[.]

# set_1 = [square, +cols, +rows, any]
# set_2 = [decrease, encrease, equal, any]

--kernel-number-type		decrease		# one of set_2
--kernels-number		[8,16]          	# number from v[0] and v[1] #potenza 2 da 4 a 32
--kernel-type 			square,equal,equal	# one combination set_1,set_2,set_2 #sempre quadrati
--kernel-shape 		 	[1,7,1,7]		# rows from v[0] and v[1], cols from v[2] and v[3]

--max-pool-type 		square,equal,equal	# one combination set_1,set_2,set_2
--max-pool-shape		[1,3,1,3]		# rows from v[0] and v[1], cols from v[2] and v[3] #2x2 fino 5x5

--strides-type			square,equal,equal	# one combination set_1,set_2,set_2
--strides			[1,2,1,2]		# rows from v[0] and v[1], cols from v[2] and v[3] #1x1 3x3 attenzione errore sui bordi

--pool-type			["all","only_end"] 	# one or more of [all, only_end]
--cnn-init			["glorot_uniform"] #fisso!
--cnn-conv-activation		["tanh"]
--cnn-dense-activation		["tanh"]

--border-mode			["same"] 		# pick one of v[.]

# --w-reg #provare prima senza i reg e constrain poi aggiungerli alla fine
# --b-reg
# --act-reg
# --w-constr
# --b-constr

#--dense-layers-numb=x -> (x*2)+1 lv
--dense-layers-numb		[0,2]			# number from v[0] and v[1] #aggiungere dropout 0.5 o 0.6
--dense-shapes			[32,64]			# number from v[0] and v[1] #togliere il primo layer di dimensione uguale al conv # intervallo 128 to 512 #fare la distribuzione uniforme nell esponente
--dense-shape-type		any     		# one of [decrease encrease equal any] # prova priam equal poi varia!

--fit-net
--epoch				50 #fisso
--patiance          20 #fisso
-aucMinaImprovement 0.01 #fisso
--learningRate      [intervallo]
--shuffle			[True,False]		# one of [True,False] #solo true
--bias				[True,False]		# one of [True,False] #solo ture (approfondire)
--batch-size			[64,128]		# number from v[0] and v[1] # da 1/10 a 1/2 dei train
--optimizer			["adadelta"]		# one of v[.] #fisso lo variamo dopo
--loss				["mse"]			# one of v[.] provare msle: con mse in mezzo all epoca schizza da 100 a 60000





