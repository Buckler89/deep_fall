--root-path             /gpfs/work/IscrC_DASHE/fall_detection/deep_fall
--script-path 			./script/
--logging
--search-strategy		random
--rnd-exp-number		1000
#--config-file

--score-path			score
--script-path			scripts
--trainset-list 		["trainset.lst"]
--case 				    case6
--test-list-names 		["testset_1.lst","testset_2.lst","testset_3.lst","testset_4.lst"]
--dev-list-names 		["devset_1.lst","devset_2.lst","devset_3.lst","devset_4.lst"]
--input-type 			spectrograms

--cnn-input-shape 		[1,129,197]
--conv-layers-numb		[1,2,3]			# pick one of v[.]

# set_1 = [square, +cols, +rows, any]
# set_2 = [decrease, encrease, equal, any]

--kernel-number-type	decrease		    # one of set_2
--kernels-number		[4,64]          	# number from v[0] and v[1]
                        #shapekernel,direttica righe, direttiva sulle colonne dei layers successivi
--kernel-type 			square,equal,equal	# one combination set_1,set_2,set_2
--kernel-shape 		 	[3,8,3,8]		# rows from v[0] and v[1], cols from v[2] and v[3]

--max-pool-type 		square,equal,equal	# one combination set_1,set_2,set_2
--max-pool-shape		[2,5,2,5]		# rows from v[0] and v[1], cols from v[2] and v[3]

--strides-type			square,equal,equal	# one combination set_1,set_2,set_2
--strides			[1,3,1,3]		# rows from v[0] and v[1], cols from v[2] and v[3] #1x1 3x3 attenzione errore sui bordi

--pool-type			["all","only_end"] 	# one or more of [all, only_end]
--cnn-init			["glorot_uniform"] 	# fisso
--cnn-conv-activation		["tanh"]
--cnn-dense-activation		["tanh"]

--border-mode			["same"] 		# pick one of v[.]

# --w-reg 		#provare prima senza i reg e constrain poi aggiungerli alla fine per raffinare il risultato
# --b-reg
# --act-reg
# --w-constr
# --b-constr0

#--dense-layers-numb=x -> (x*2)+1 lv
--dense-layers-numb		[0,2]			# number from v[0] and v[1]
--dense-shapes			[128,4096]		# number from v[0] and v[1]
--dense-shape-type		equal     	# one of [decrease encrease equal any] # prova priam equal poi varia!

--dropout			[True,False]
--drop-rate			[0.5,0.6]		# distribuzione normale m=v[1]+v[2]/2, sigma=v[1]-v[2]/4 #emap dice fisso o eventualmente da 0.4 a 0.6

--fit-net
--epoch				1000 			    # fisso
--patiance          40       			# fisso
--aucMinImp 		0.0001	    		# fisso
--optimizer			["adam"]		# one of v[.] #fisso lo variamo dopo
--learning-rate 	[0.0001,0.01]            #da verificare se farla cambiare

--shuffle			[True]			# one of [True,False]
--bias				[True]			# one of [True,False] 			#solo ture (approfondire)
--batch-size		["1/10","1/4"]		# number from v[0] and v[1] 		# da 1/10 a 1/2 dei train
--loss				["msle"]		# one of v[.] provare msle: con mse in mezzo all epoca schizza da 100 a 60000









